{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027665376663208008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 52,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9fabc5e0334e42b459023edce2381a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014791250228881836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 579,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb09891521d4f65b3b6ba7240149d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01307225227355957,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 4305025,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5a8ac400c449d19289c1c5366ea5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017726421356201172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1332809049,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea9dc6588074fe9a73d488aa14c916c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'deberta.embeddings.word_embeddings._weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
    "model.eval()\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/work/hack/train_dataset.csv\")\n",
    "test = pd.read_csv(\"/work/hack/test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [03:47<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "train_vectors = []\n",
    "for i in tqdm(range(0, len(train), batch_size)):\n",
    "    left, right = i, min(i + batch_size, len(train))\n",
    "    encoded_input = tokenizer(train['text'].iloc[left:right].tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    encoded_input = encoded_input.to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    sentence_embeddings = list(mean_pooling(model_output, encoded_input['attention_mask']).detach().cpu())\n",
    "    train_vectors.extend(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.4176e-02, -5.4999e-02, -2.0382e-02,  4.7547e-02, -2.1778e-01,\n",
       "        -2.1337e-01, -1.1325e-01, -6.4509e-02, -9.6143e-02, -2.4505e-01,\n",
       "        -1.1256e-01,  1.8584e-02, -2.8720e+00, -6.9643e-02,  6.2274e-02,\n",
       "         1.6515e+00,  1.7017e+00, -1.5462e-01, -1.4297e-02, -1.4868e+00,\n",
       "        -2.0909e-01,  6.4854e-03, -2.3828e+00,  1.1335e-03,  1.0966e-01,\n",
       "        -6.3492e-02, -1.8410e-01, -1.3188e-01, -1.8072e-01, -3.4738e-01,\n",
       "        -2.2863e-01, -5.4337e-02, -3.8867e-01,  1.9981e+00, -2.0197e-01,\n",
       "        -6.4367e-03,  1.7863e-01,  1.5049e-01, -9.4470e-02, -7.8394e-02,\n",
       "        -1.9021e-01, -9.7756e-02,  7.9620e-02, -7.4524e-02,  2.0910e-01,\n",
       "         1.0323e-01, -9.1274e-02,  2.3454e+00,  1.5543e-01, -2.5014e-01,\n",
       "         2.2304e-02,  1.8366e-01,  9.6988e-02, -1.2164e-01, -3.8810e-02,\n",
       "        -1.4663e+00, -5.5926e-02, -3.3733e-01,  5.3179e-02,  5.2299e-01,\n",
       "         1.2981e-02, -1.6276e-02,  3.9341e-02, -8.6249e-02, -2.0718e-01,\n",
       "         7.3246e-01, -1.1070e-01,  2.9733e-02, -3.0292e-01,  5.7904e-02,\n",
       "         1.7970e-01,  3.5723e-02, -2.0002e-01, -6.6492e-02,  9.9235e-02,\n",
       "         4.5422e-02, -3.0766e-02, -2.4110e-01,  5.2297e-03,  1.8183e-01,\n",
       "         5.8539e-02, -6.7703e-03,  8.3974e-02, -3.6942e-01,  5.9141e-02,\n",
       "        -9.5643e-02,  3.6906e-02,  2.2574e-02, -1.6880e-01, -3.9973e-02,\n",
       "         1.3208e-01,  2.1604e-01,  6.4605e-02,  4.2100e-01, -4.0680e-02,\n",
       "        -2.2899e-01, -1.7038e-01, -6.8341e-02, -1.2179e-01, -1.0773e-01,\n",
       "        -2.9886e-02,  4.2877e-02,  5.7457e-02,  2.2611e-01, -3.3247e-01,\n",
       "         1.2892e-01, -1.1430e-01, -9.4072e-02, -2.9650e-01,  2.8002e+00,\n",
       "         1.2544e-01, -6.7371e-02, -1.0903e-01, -1.6164e-01,  1.5943e-01,\n",
       "        -2.3982e-02, -1.3917e-01, -1.0959e-02, -2.1757e-01, -1.0414e-01,\n",
       "         1.8700e-01,  1.5998e-01, -3.0969e+00, -1.8792e+00, -9.7068e-02,\n",
       "         1.2051e-01,  1.0216e-01, -1.4560e-01,  7.7681e-02, -2.8808e-02,\n",
       "        -5.7232e-03, -1.6595e-01,  3.5058e-01, -1.2502e-01,  2.8163e-02,\n",
       "         3.1359e-02,  1.2043e-02, -6.8532e-01, -6.8562e-02,  1.3751e-01,\n",
       "        -1.4393e-02, -5.4890e-02,  9.3104e-02, -1.2751e-02,  1.3923e-01,\n",
       "        -1.7843e-02,  1.7951e-01, -3.0692e-01, -1.9573e-01,  1.2325e-01,\n",
       "         2.3248e-01,  7.6491e-02,  2.7166e-02,  2.8359e-02, -3.5759e-02,\n",
       "         5.9058e-02,  1.3881e-01,  4.0688e-02,  8.2097e-03, -1.1367e-01,\n",
       "         1.3612e-01, -1.3809e-02,  7.7765e-03, -8.4222e-02, -6.2922e-02,\n",
       "         4.8154e-01,  3.1433e-02,  2.7437e-02,  1.1403e-02,  9.0996e-02,\n",
       "        -1.2708e-01, -2.0483e-01,  5.8285e-03,  3.8012e-02, -1.2097e-01,\n",
       "        -1.7401e-03, -6.5470e-01,  6.0945e-02, -5.1597e-03,  2.3682e-03,\n",
       "         1.9672e-01,  9.2152e-03,  4.6487e+00,  6.3501e-02, -9.6915e-03,\n",
       "         1.1938e-01,  1.5586e-01,  1.4657e-01,  7.2274e-02,  3.1689e+00,\n",
       "        -1.3601e-01, -2.7713e-02, -6.0326e-02,  2.5349e-02, -2.4699e-02,\n",
       "        -5.6571e-02,  3.4882e-02, -1.1638e-02, -7.1233e-01,  5.3441e-02,\n",
       "        -5.5038e-02, -6.3328e-02, -5.7221e-03,  3.7891e-02,  6.6024e-02,\n",
       "        -8.6699e-02, -1.1263e-01,  5.2725e-03,  4.4132e-02,  1.4315e-01,\n",
       "        -3.5306e+00, -4.1464e-02, -8.2119e-02,  1.2836e-02,  2.4086e-02,\n",
       "         1.1674e-01, -2.2214e-02, -1.0875e-01,  1.2223e+00,  1.5406e+00,\n",
       "        -7.5166e-02,  1.3477e-01, -7.0670e-01, -6.1614e-02,  4.8081e+00,\n",
       "        -6.7627e-01, -2.9094e+00,  1.3275e-02,  1.0567e-01, -1.4727e-01,\n",
       "         8.7185e-02,  1.2684e-01,  2.8739e-02, -1.5833e-01,  4.4480e-02,\n",
       "         4.7086e-02, -5.2403e-02, -1.3521e-02,  1.8493e-01, -6.1051e-02,\n",
       "        -5.1687e-02,  1.3726e-01, -3.2300e-02, -6.0702e-02, -3.1183e+00,\n",
       "        -9.0036e-02, -2.9798e-02, -4.8795e-02,  2.8070e-02,  9.7262e-02,\n",
       "        -2.0048e-01, -1.7637e-01, -1.1100e-01, -1.5637e-01,  3.5812e-02,\n",
       "        -8.4189e-02, -1.2849e-01,  5.1461e-02, -3.1136e-01,  5.1258e-01,\n",
       "         2.8876e-02, -5.5411e-02, -1.3138e-01, -1.1027e-01, -8.3693e-02,\n",
       "        -8.1696e-02, -1.6704e-01,  4.2505e-01,  1.0320e-01,  7.3283e-02,\n",
       "        -7.7736e-02, -3.8019e-02,  4.1849e-02,  1.0820e-01, -8.1109e-02,\n",
       "         1.5412e-01, -2.2310e-02,  1.6720e-02, -1.5220e-01, -1.2156e-01,\n",
       "         4.8002e+00, -8.1333e-01,  3.6706e-02,  3.4352e-02, -1.6717e-02,\n",
       "         4.7299e-02,  6.4236e-02, -3.4218e-01,  2.5654e-01,  4.6777e-02,\n",
       "         4.1571e-02, -1.1796e-01, -3.7779e-02,  1.3843e-01, -2.4518e-01,\n",
       "         1.0887e-02, -6.5948e-02, -2.4231e-01,  1.7140e-01,  1.2926e-03,\n",
       "        -5.2937e-02, -2.5417e-01, -1.2786e-01, -5.0724e-02,  7.2674e-02,\n",
       "        -1.9678e+00, -5.7258e-02, -7.8469e-02, -2.0537e-01, -1.0946e-01,\n",
       "        -6.3167e-01, -2.2214e+00,  4.1668e-02, -6.0273e-02, -5.4941e-02,\n",
       "         2.5724e-01, -5.1306e-02, -1.1465e-01,  1.2042e-01, -5.7549e-02,\n",
       "         5.7344e+00, -1.6114e-01, -1.4410e-01,  1.2572e-01,  3.3089e-01,\n",
       "         6.7364e-01,  5.2178e-02,  2.6300e-01, -1.3675e+00, -1.0472e-01,\n",
       "         4.7795e-02, -2.6758e-02,  2.1319e-02,  1.5419e-01,  1.8200e-02,\n",
       "        -9.6199e-02,  7.6067e-01, -2.0657e-02, -1.1054e-01,  2.3025e+00,\n",
       "         2.8248e-02,  6.6574e-02, -1.8813e-02, -1.4928e-01,  1.7780e-01,\n",
       "        -5.2277e-03, -1.1034e-01,  7.2839e-02,  6.1197e-02,  1.1527e-01,\n",
       "         9.8707e-01, -9.1986e-02, -4.4316e-03,  7.2375e-03, -1.6660e-01,\n",
       "        -7.2362e-02, -1.0382e-01,  5.9507e-02, -1.4256e-01, -2.8626e-01,\n",
       "         5.8104e-02,  5.0361e-02,  1.3653e-01, -1.4005e-01, -1.6732e-01,\n",
       "        -8.8123e-03,  5.5891e-01, -9.7874e-03,  1.6734e-01,  1.9035e-01,\n",
       "         4.6400e-01, -8.6013e-02,  3.4033e-02, -4.9602e-02, -5.4888e-03,\n",
       "        -6.0331e-02,  4.9776e-02,  1.7015e-01, -1.2277e-01, -7.6848e-02,\n",
       "        -2.8803e+00, -8.3654e-02,  9.5706e-03,  2.0700e+00,  3.8423e-01,\n",
       "         4.9004e-02, -5.5803e-02,  7.2473e-02,  1.1090e+00,  4.7343e-02,\n",
       "        -1.0188e-01, -5.8264e-02, -5.0484e-02, -7.4326e-02,  1.5992e-01,\n",
       "        -6.3453e-02, -1.5496e-01,  1.1842e-01,  2.2546e-01,  1.8443e-01,\n",
       "         2.2642e-01, -9.5942e-02, -2.4482e-02, -2.2027e-01, -1.5453e-01,\n",
       "        -9.8418e-02, -2.5766e-01,  1.0409e-01,  2.8693e-01,  6.8049e-02,\n",
       "         9.6246e-02,  2.4283e+00,  1.0221e-01,  1.6614e-02,  4.6264e-01,\n",
       "         2.5773e-01, -6.1741e-02,  7.4791e-02, -8.4067e-02, -4.5133e-02,\n",
       "         2.0390e-02, -1.2977e-01,  2.3783e-01,  1.3109e-02, -1.7107e+00,\n",
       "        -1.5346e-02, -2.1520e-03, -1.4306e-01, -1.8936e-02, -1.7491e-01,\n",
       "        -1.9605e-02,  1.7854e-02,  2.3408e-02, -7.6417e-03,  6.2973e-01,\n",
       "        -1.3907e-01,  6.1480e-02,  3.7311e-02, -1.9694e-01,  7.6516e-02,\n",
       "         1.7976e+00,  8.9971e-02,  1.7224e-01, -2.8554e-02,  1.1868e+00,\n",
       "        -3.6436e-02,  3.9979e-02, -2.7936e-02,  9.2562e-02, -6.2004e-02,\n",
       "         3.1869e-02,  2.0297e-01,  3.6115e-02,  1.1809e-01,  8.9518e-02,\n",
       "        -9.1097e-03,  1.1016e-02, -4.1458e-02,  1.4243e-01, -1.0758e-01,\n",
       "        -2.0083e-01,  2.1717e-02, -1.0156e-01,  7.4683e-02, -9.2008e-03,\n",
       "         7.1773e-02,  1.3120e-01,  8.7081e-02,  1.2359e-01, -2.1428e-03,\n",
       "         2.5489e-02, -3.8675e-02,  8.2338e-02, -1.2428e-01, -1.7278e-02,\n",
       "         9.9238e-01,  1.0104e-03,  6.1709e-02,  3.4428e-02, -2.8703e-03,\n",
       "         5.6373e-02,  1.3328e-02,  2.5298e-01,  1.8549e-01, -1.6602e-01,\n",
       "         8.8600e-02, -1.4446e-02,  1.6126e-01, -4.9502e-03, -5.4820e-02,\n",
       "        -1.1869e-01, -8.0765e-02,  2.7475e-03,  6.1182e-03,  8.5094e-02,\n",
       "         7.1651e-01,  9.9168e-02,  8.4305e-01,  9.5080e-01, -8.1246e-02,\n",
       "        -6.2223e-01, -3.1286e-02,  3.9551e-02, -1.1042e-01, -1.4178e-01,\n",
       "        -1.7589e-01,  3.9451e-02,  4.0638e-02,  3.6439e-02, -4.2268e-02,\n",
       "        -4.3948e-02,  1.3589e-02, -5.2017e-02, -1.8102e-01,  3.0893e-02,\n",
       "         2.4886e+00, -3.5100e+00,  5.3049e-02, -2.0581e-01,  1.2534e-01,\n",
       "        -9.5854e-02,  2.4210e-01,  1.6235e+00, -3.3877e-02,  2.5017e-02,\n",
       "        -1.5381e-01, -4.6075e-02, -5.1036e-02,  3.2827e+00, -1.9009e-01,\n",
       "        -1.4797e-02, -3.1032e-02, -5.6163e-02,  9.8528e-02, -1.9481e-01,\n",
       "        -1.7970e-01, -5.0128e-02, -2.4491e-01, -5.4777e-02, -4.1613e-02,\n",
       "        -1.5574e-01, -6.5922e-01, -1.2776e-01,  2.3942e-01, -1.7493e+00,\n",
       "        -9.7096e-03, -1.5972e+01, -1.5380e-01,  2.8849e-02, -7.6640e-02,\n",
       "         5.1431e-01,  5.8428e-02,  3.5753e-02, -4.3057e-04,  1.7422e-01,\n",
       "        -3.2373e-02, -2.1735e-02, -2.0904e-01,  9.9482e-02, -8.3085e-02,\n",
       "        -5.0810e-02, -1.6859e-01, -2.2583e-02, -2.7856e-01, -1.5463e-01,\n",
       "         1.1377e-01, -1.8044e-01,  1.2932e-01,  8.4583e-02,  1.1630e-02,\n",
       "        -1.3609e-01, -4.4559e-02,  1.1079e-01,  3.3863e-02,  7.0460e-02,\n",
       "         1.6625e-01, -1.1563e-02,  1.9976e-01,  1.4632e-01, -2.9230e-02,\n",
       "        -4.2340e-03, -8.6229e-02, -1.8719e-01,  1.7624e-01,  2.2301e-02,\n",
       "         3.4515e-02, -4.2375e-02, -5.3767e-02,  5.8392e-01, -7.5713e-02,\n",
       "         3.5484e-02,  5.8045e-02, -2.2359e-01, -1.3554e-01,  7.7820e-02,\n",
       "         3.6579e-02,  1.2525e-01,  5.6283e-02, -1.6358e-01,  9.2458e-02,\n",
       "         1.3720e-02, -3.4061e-02,  5.0629e-02, -5.9176e-01,  9.1467e-03,\n",
       "        -2.4164e-01, -1.0809e-01, -1.0946e-01,  2.0945e-02,  5.4075e-02,\n",
       "        -5.2146e-02, -1.0082e-01,  5.2263e-02,  9.1353e-02, -1.7385e-01,\n",
       "        -2.1221e-01,  2.8499e-01,  3.6041e-02,  3.2630e-02,  1.3367e-01,\n",
       "         6.3195e-02, -1.7247e-01,  7.1692e-02, -1.9398e-01, -6.8447e-03,\n",
       "        -4.2344e-02,  1.1136e-01, -1.0966e-01, -3.2767e-02, -1.0472e-01,\n",
       "        -3.2952e-01, -2.0087e-01, -3.6675e-02,  1.2777e-01, -2.8751e-01,\n",
       "         1.7490e-02,  1.5637e-01, -6.2030e-02,  1.5663e-01, -1.8918e-01,\n",
       "         3.6840e-02, -3.8520e-03, -1.8670e-02, -2.0996e+00,  7.1493e-01,\n",
       "         3.9320e-01, -5.9991e-02, -2.3029e-02,  1.1258e-01,  1.0086e-02,\n",
       "         1.4814e-01,  7.7067e-02, -2.6631e+00,  1.1027e-01,  8.1222e-02,\n",
       "        -4.9600e-03, -1.1393e-01, -1.3054e-01,  1.7714e-01,  4.6121e-03,\n",
       "        -3.1072e-02,  7.3873e-02,  1.1220e-01,  2.3068e-02, -7.8374e-01,\n",
       "        -1.4908e+00,  5.4628e-02, -2.7015e+00,  1.7725e-01,  2.0149e-01,\n",
       "         3.3284e-02,  9.6154e-02,  1.0315e-01,  1.7400e-01,  3.1749e-01,\n",
       "        -9.4805e-02,  9.1387e-02, -1.2245e-01, -2.2377e+00,  1.9147e-01,\n",
       "         1.5965e-01, -3.2620e-01, -4.5277e-02,  7.5653e-02,  2.9430e-01,\n",
       "         1.2677e-01,  7.9767e-02, -1.5428e-01, -7.8557e-01, -7.7815e-02,\n",
       "        -1.5811e-03, -2.0349e-02,  3.2321e-01, -9.6238e-03, -1.9643e-01,\n",
       "         1.0914e-02, -2.0514e-01,  2.9700e-02, -1.9264e-01, -6.6026e-02,\n",
       "        -1.8973e-01,  1.6769e-01, -5.6218e-02, -3.6626e-02, -5.2942e-02,\n",
       "         7.5668e-02,  6.4787e-03,  5.7916e-02,  1.4558e-01, -2.0366e-01,\n",
       "        -7.6000e-02, -1.2585e-01, -5.1570e-01,  2.3414e-01, -1.4133e-01,\n",
       "        -2.3260e-01,  8.2294e-01,  5.9892e-02,  2.1122e-02, -1.2004e-01,\n",
       "         3.5174e-02, -1.5579e-01,  4.2844e-02,  1.3654e-02, -2.1870e+00,\n",
       "         3.9491e-02, -1.3855e-01,  4.4941e-01,  1.8464e-01,  4.3699e-01,\n",
       "        -2.4334e-01, -2.0018e-01, -2.0565e-01,  5.1072e-03, -7.3913e-02,\n",
       "        -2.2946e-02,  1.5412e-02,  1.8387e-01, -4.0377e-02, -2.9108e-02,\n",
       "         8.9730e-02,  1.6421e+00,  6.1743e-02, -1.2936e-01, -9.4209e-03,\n",
       "        -1.5457e-01,  2.4987e-01,  7.3947e-02, -7.2799e-02, -1.5806e-01,\n",
       "        -4.2642e-02, -1.2790e-01,  7.6108e-03, -1.2190e-01,  3.9569e-02,\n",
       "        -5.5415e-03, -1.6170e-02, -9.1699e-02,  4.4526e+00, -7.0280e-04,\n",
       "         8.6404e-02, -2.4098e-01,  9.7593e-02, -1.2898e-01, -1.6104e-01,\n",
       "        -1.2744e-01, -8.1347e-02,  1.7403e-02])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:56<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "test_vectors = []\n",
    "for i in tqdm(range(0, len(test), batch_size)):\n",
    "    left, right = i, min(i + batch_size, len(test))\n",
    "    encoded_input = tokenizer(test['text'].iloc[left:right].tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    encoded_input = encoded_input.to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    sentence_embeddings = list(mean_pooling(model_output, encoded_input['attention_mask']).detach().cpu())\n",
    "    test_vectors.extend(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-85-2f85413d802e>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  train_vectors = np.array(train_vectors)\n",
      "<ipython-input-85-2f85413d802e>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_vectors = np.array(train_vectors)\n"
     ]
    }
   ],
   "source": [
    "train_vectors = np.array(train_vectors)\n",
    "for i in range(len(train_vectors)):\n",
    "    train_vectors[i] = train_vectors[i].numpy()\n",
    "train_res = np.stack(train_vectors).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-b39f6aa2edee>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  test_vectors = np.array(test_vectors)\n",
      "<ipython-input-86-b39f6aa2edee>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_vectors = np.array(test_vectors)\n"
     ]
    }
   ],
   "source": [
    "test_vectors = np.array(test_vectors)\n",
    "for i in range(len(test_vectors)):\n",
    "    test_vectors[i] = test_vectors[i].numpy()\n",
    "test_res = np.stack(test_vectors).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train['subject'] = le.fit_transform(train['subject'])\n",
    "test['subject'] = le.transform(test['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(train_res, train['subject'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(test_res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06777060263111757"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test['subject'].tolist(), y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
