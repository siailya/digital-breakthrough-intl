{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2c706157-284f-4f04-92f0-0da4ae317c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, model.num_classes), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48356a8a-fd02-403a-9d43-ae5f1fcf24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "    \n",
    "from transformers import AutoModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "class AttentionPoolerV1(nn.Module):\n",
    "    \"\"\"\n",
    "    самая простая реализация\n",
    "    веса токенов одни и те же для всех лейблов.\n",
    "    по сути только помогает игнорить какой-то общий слабый сигнал для всех классов: например, тишина.\n",
    "    \"\"\"\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.pooler = nn.Linear(d, 1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        d = x.shape[-1]\n",
    "        w = self.pooler(x) / d ** 0.5  # [N, T, 1]\n",
    "        w = w + (1.0 - mask[:, :, None].float()) * -10000.0\n",
    "        w = torch.softmax(w, dim=1)  # [N, T, 1]\n",
    "        x = (x * w).sum(1)  # [N, D]\n",
    "        return x\n",
    "\n",
    "class AttentionPoolerV2(nn.Module):\n",
    "    \"\"\"\n",
    "    v1 + только в качестве mlp взята линейная модель с нелинейностью\n",
    "    \"\"\"\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.pooler = nn.Sequential(\n",
    "            nn.Linear(d, d),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        w = self.pooler(x)  # [N, T, 1]\n",
    "        w = w + (1.0 - mask[:, :, None].float()) * -10000.0\n",
    "        w = torch.softmax(w, dim=1)  # [N, T, 1]\n",
    "        x = (x * w).sum(1)  # [N, D]\n",
    "        return x\n",
    "    \n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class BertMPModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, inp_dim=1024, device='cuda'):\n",
    "        super(BertMPModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        \n",
    "        self.base_model = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(inp_dim, 2) # output features from bert is 768 and 2 is ur number of labels\n",
    "        self.bn = nn.BatchNorm1d(inp_dim)\n",
    "        self.poooling = MeanPooling()\n",
    "        # self.poooling = AttentionPooling(inp_dim)\n",
    "        # self.poooling = AttentionPoolerV2(inp_dim)\n",
    "        self.fc = nn.Linear(inp_dim, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "        out = self.poooling(outputs.last_hidden_state, attention_mask)\n",
    "        out = self.bn(out)\n",
    "        outputs = self.fc(out)\n",
    "        return SequenceClassifierOutput(logits=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140818e-98ff-4ba5-b7c1-88ea61a0fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b831d9f395bc4f1790bcdded7f0069b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19038 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5936dae243b438abea84ffb34ecf8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4509 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='53' max='47600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   53/47600 00:23 < 6:10:47, 2.14 it/s, Epoch 0.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoConfig\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch.nn as nn\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels),\n",
    "        \"f1_weighted\": f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "        }\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    return logits[0]\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512, padding=True)\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"train_dataset.csv\")\n",
    "# train, X_test = train_test_split(train, stratify=train['subject'], train_size=0.1)\n",
    "test = pd.read_csv(\"test_dataset.csv\")\n",
    "# train = train.rename(columns={\"subject\": \"labels\"})\n",
    "# test = test.rename(columns={\"subject\": \"labels\"})\n",
    "\n",
    "train = train.rename(columns={\"group_subject\": \"labels\"})\n",
    "test = test.rename(columns={\"group_subject\": \"labels\"})\n",
    "\n",
    "le = LabelEncoder()\n",
    "train['labels'] = le.fit_transform(train['labels'])\n",
    "test['labels'] = le.transform(test['labels'])\n",
    "\n",
    "\n",
    "model_name = \"ai-forever/sbert_large_nlu_ru\"\n",
    "batch_size = 4\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = train_dataset\n",
    "ds['test'] = test_dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BertMPModel(model_name, len(le.classes_))\n",
    "\n",
    "tokenized_ds = ds.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"subject_model_on_my_clear_data/bert_mp_group\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    eval_accumulation_steps=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    lr_scheduler_type=\"cosine\",  \n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"none\",\n",
    "    label_smoothing_factor=0.01,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    #preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fed2ef6c-a0c7-454b-a630-0806a1f356f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_dataset_with_synt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b389b09a-599b-40ab-b93d-a75ce8c93c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c16e904050>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoConfig\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch.nn as nn\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bff6c67-9b5a-4271-b9a8-c2e2b1e4a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(\"subject_model_on_my_clear_data/checkpoint-40581\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b37757d-2fb1-4e70-b496-3de51a2d7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('models/label_encoder_mp.pkl', 'wb') as f:\n",
    "#     pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b42065-55e7-419b-8dcc-b8022ec8df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), \"model/bert_ap.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bef8632-c42d-4e84-9f60-91cdb488bbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Группа тем</th>\n",
       "      <th>Тема</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>9738</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>9739</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>9740</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>9741</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9742</th>\n",
       "      <td>9742</td>\n",
       "      <td>Физическая культура и спорт</td>\n",
       "      <td>Строительство спортивной инфраструктуры</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9743 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                   Группа тем  \\\n",
       "0        0  Физическая культура и спорт   \n",
       "1        1  Физическая культура и спорт   \n",
       "2        2  Физическая культура и спорт   \n",
       "3        3  Физическая культура и спорт   \n",
       "4        4  Физическая культура и спорт   \n",
       "...    ...                          ...   \n",
       "9738  9738  Физическая культура и спорт   \n",
       "9739  9739  Физическая культура и спорт   \n",
       "9740  9740  Физическая культура и спорт   \n",
       "9741  9741  Физическая культура и спорт   \n",
       "9742  9742  Физическая культура и спорт   \n",
       "\n",
       "                                         Тема  \n",
       "0     Строительство спортивной инфраструктуры  \n",
       "1     Строительство спортивной инфраструктуры  \n",
       "2     Строительство спортивной инфраструктуры  \n",
       "3     Строительство спортивной инфраструктуры  \n",
       "4     Строительство спортивной инфраструктуры  \n",
       "...                                       ...  \n",
       "9738  Строительство спортивной инфраструктуры  \n",
       "9739  Строительство спортивной инфраструктуры  \n",
       "9740  Строительство спортивной инфраструктуры  \n",
       "9741  Строительство спортивной инфраструктуры  \n",
       "9742  Строительство спортивной инфраструктуры  \n",
       "\n",
       "[9743 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78cbd91d-83e1-4f6a-a849-6ce701005bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d79e51b9-842b-4ce2-a3e9-e76df893e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cfc8954-ff50-4526-ab9c-0c6278d9e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns = {\n",
    "    \"Текст инцидента\": \"text\",\n",
    "}\n",
    "test = test.rename(columns=rename_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e96e599-f494-47f5-9623-eb371380974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['text'].apply(lambda x: re.sub(r'http\\S+', '', x)) \n",
    "test['text'] = test['text'].apply(lambda x: re.sub('<[^<]+?>', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "076fce5f-6728-4f8c-bfa8-6f87121f3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models/label_encoder_mp.pkl', 'rb') as pkl_file:\n",
    "    le = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "454158de-ca8a-4e11-baad-1cfda3b83f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ai-forever/sbert_large_nlu_ru\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BertMPModel(model_name, len(le.classes_))\n",
    "model.load_state_dict(torch.load(\"models/bert_mp.pth\"))\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b038ebaa-8260-405e-8b24-7e4c22ed1611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Архитектура города', 'Архитектура города'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_[[1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e94e445e-2b1c-430d-a91d-6c43eb06c463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 609/609 [02:34<00:00,  3.95it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "for batch in tqdm(DataLoader(test['text'].to_list(), batch_size=16, shuffle=False)):\n",
    "    tokenized = tokenizer(batch, truncation=True, max_length=512, padding=True, return_tensors='pt')\n",
    "    tokenized.pop(\"token_type_ids\")\n",
    "    tokenized = {k: v.cuda() for k,v in tokenized.items()}\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokenized)\n",
    "        predictions = np.argmax(output.logits.cpu(), axis=1)\n",
    "    all_preds += [le.classes_[predictions]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c2e733e6-904c-44c8-aec7-21ec4e3c2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = pd.read_csv('first_submit.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "46eab34d-19cc-4c3e-9587-484723a8d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg['Тема'] = np.concatenate(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90acaf55-b4bd-4d1f-b801-69ca9c864f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Тема</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ремонт спортивных учреждений</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Подтопление автомобильных дорог</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Содержание больниц</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Дети и многодетные семьи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Оказание гос. соц. помощи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>★ Неисправные фонари освещения</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>Оказание гос. соц. помощи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>Безопасность общественных пространств</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>Оказание гос. соц. помощи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9742</th>\n",
       "      <td>Дистанционное образование</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9743 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Тема\n",
       "0              Ремонт спортивных учреждений\n",
       "1           Подтопление автомобильных дорог\n",
       "2                        Содержание больниц\n",
       "3                  Дети и многодетные семьи\n",
       "4                 Оказание гос. соц. помощи\n",
       "...                                     ...\n",
       "9738         ★ Неисправные фонари освещения\n",
       "9739              Оказание гос. соц. помощи\n",
       "9740  Безопасность общественных пространств\n",
       "9741              Оказание гос. соц. помощи\n",
       "9742              Дистанционное образование\n",
       "\n",
       "[9743 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.concatenate(all_preds), columns=['Тема'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff919770-dc25-4a20-b0b8-1fb592794237",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.to_csv('second_submit.csv', sep = ';', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5c898-bdb2-4c14-b083-0b4b28349541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa82b56-8058-4d43-9424-e50f54706112",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"subject_model_on_my_clear_data\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    eval_accumulation_steps=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    lr_scheduler_type=\"cosine\",  \n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"none\",\n",
    "    label_smoothing_factor=0.01,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer1 = CustomTrainer(\n",
    "    model=model1,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    #preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f64f2648-6893-4702-9c0f-4a62fffca997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1128' max='1128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1128/1128 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.757267475128174,\n",
       " 'eval_accuracy': {'accuracy': 0.5657573741406077},\n",
       " 'eval_f1_weighted': {'f1': 0.5604479363245909},\n",
       " 'eval_runtime': 99.5047,\n",
       " 'eval_samples_per_second': 45.314,\n",
       " 'eval_steps_per_second': 11.336}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer1.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab331f-7573-4b9f-927b-a448cc48638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filename, sep = ';', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ec8cc-9b39-4a73-80b1-e1b0235bcd93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec193d-43ca-4aeb-917c-0650dddf0795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb5877-bb1e-4519-b3d7-15e2fb099a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
