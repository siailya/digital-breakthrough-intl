{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sage.spelling_corruption import SBSCConfig, SBSCCorruptor\n",
    "from sage.utils import DatasetsAvailable, load_available_dataset_from_hf, draw_and_save_errors_distributions_comparison_charts\n",
    "from sage.spelling_corruption.sbsc.labeler import process_mistypings\n",
    "from sage.spelling_corruption import CharAugConfig, CharAugCorruptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/work/hack/train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'cointegrated/rut5-base-paraphraser'\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model.cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(text, beams=5, grams=4, do_sample=False):\n",
    "    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n",
    "    max_size = int(x.input_ids.shape[1] * 1.5 + 10)\n",
    "    out = model.generate(**x, encoder_no_repeat_ngram_size=grams, num_beams=beams, max_length=max_size, do_sample=do_sample)\n",
    "    return tokenizer.batch_decode(out, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [20:38<00:00,  6.88s/it]\n"
     ]
    }
   ],
   "source": [
    "for_paraphrase = train[train['text'].str.len() > 20].sample(frac=0.10)\n",
    "texts = for_paraphrase['text'].tolist()\n",
    "batch_size = 10\n",
    "paraphrased_data = []\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    left, right = i, min(i + batch_size, len(texts))\n",
    "    paraphrased_data.extend(paraphrase(texts[left:right]))\n",
    "for_paraphrase['text'] = paraphrased_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset russian_spellcheck_benchmark (/root/.cache/huggingface/datasets/ai-forever___russian_spellcheck_benchmark/RUSpellRU/0.0.1/87bfa2950c7b82ec565b4da426533874af24d25436ad08dba065a45895ad3945)\n",
      "100%|██████████| 2000/2000 [00:20<00:00, 98.68it/s] \n"
     ]
    }
   ],
   "source": [
    "corruptor = SBSCCorruptor.from_default_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1803/1803 [00:00<00:00, 4967.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for_sbsc_corrupt = train.sample(frac=0.1)\n",
    "for_sbsc_corrupt['text'] = corruptor.batch_corrupt(for_sbsc_corrupt['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_char_level_corrupt = train.sample(frac=0.1)\n",
    "config = CharAugConfig(\n",
    "    unit_prob=0.1, # proportion of characters that is going to undergo edits\n",
    "    min_aug=1, # minimum number of edits\n",
    "    max_aug=5, # maximum number of edits \n",
    "    mult_num=3 # `multiply` edit\n",
    ")\n",
    "corruptor = CharAugCorruptor.from_config(config)\n",
    "for_char_level_corrupt['text'] = corruptor.batch_corrupt(for_char_level_corrupt['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.concat([train, for_paraphrase, for_sbsc_corrupt, for_char_level_corrupt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv(\"train_dataset_augs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
